{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2 - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "- Examines linear relationship between two variables, can be positive or negative\n",
    "- $ y = \\beta_0X + \\alpha $ where $\\beta_0$ is the slope and $\\alpha$ is the intercept\n",
    "- In linear regression, we are predicting a continous variable\n",
    "- trying to minimize the errors to find line of best fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_boston()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "target_respone = pd.DataFrame(data.target, columns=['MEDV'])\n",
    "# target or Y is set as median value and other variables are set as regressors\n",
    "#because we are trying to predict median house prices in boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared (uncentered):</th>      <td>   0.901</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.901</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   4615.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 29 Sep 2022</td> <th>  Prob (F-statistic):</th>          <td>3.74e-256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:59:50</td>     <th>  Log-Likelihood:    </th>          <td> -1747.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th>          <td>   3496.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   505</td>      <th>  BIC:               </th>          <td>   3500.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th> <td>    3.6534</td> <td>    0.054</td> <td>   67.930</td> <td> 0.000</td> <td>    3.548</td> <td>    3.759</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>83.295</td> <th>  Durbin-Watson:     </th> <td>   0.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 152.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.955</td> <th>  Prob(JB):          </th> <td>7.65e-34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.894</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                   MEDV   R-squared (uncentered):                   0.901\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.901\n",
       "Method:                 Least Squares   F-statistic:                              4615.\n",
       "Date:                Thu, 29 Sep 2022   Prob (F-statistic):                   3.74e-256\n",
       "Time:                        15:59:50   Log-Likelihood:                         -1747.1\n",
       "No. Observations:                 506   AIC:                                      3496.\n",
       "Df Residuals:                     505   BIC:                                      3500.\n",
       "Df Model:                           1                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "RM             3.6534      0.054     67.930      0.000       3.548       3.759\n",
       "==============================================================================\n",
       "Omnibus:                       83.295   Durbin-Watson:                   0.493\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              152.507\n",
       "Skew:                           0.955   Prob(JB):                     7.65e-34\n",
       "Kurtosis:                       4.894   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[\"RM\"]\n",
    "y = target_respone[\"MEDV\"]\n",
    "\n",
    "# Note the difference in argument order\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we are trying to minimise square of distance from regression line using OLS. \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.00384338 25.02556238 30.56759672 28.60703649 27.94352423]\n",
      "0.7406426641094095\n",
      "[-1.08011358e-01  4.64204584e-02  2.05586264e-02  2.68673382e+00\n",
      " -1.77666112e+01  3.80986521e+00  6.92224640e-04 -1.47556685e+00\n",
      "  3.06049479e-01 -1.23345939e-02 -9.52747232e-01  9.31168327e-03\n",
      " -5.24758378e-01]\n",
      "36.45948838509016\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(df, target_respone['MEDV'])\n",
    "predictions = lm.predict(df)\n",
    "print(predictions[0:5])\n",
    "print(lm.score(df,target_respone['MEDV'])) ## r^2 score\n",
    "print(lm.coef_)\n",
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Squares\n",
    "- Linear Model:\n",
    "  - $ y = \\beta^tX + \\alpha $\n",
    "  - without loss of generaility it is $ y = \\begin{bmatrix} \\alpha & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ \\beta \\end{bmatrix} $\n",
    "  - $ \\hat{A} = \\begin{bmatrix} a_1^T & 1 \\\\ ... & ... \\\\ a_1^T & 1 \\end{bmatrix} $\n",
    "  \n",
    "  - $\\hat{x} = \\begin{bmatrix} x \\\\ \\beta \\end{bmatrix} $\n",
    "- Opt: $ \\hat{x} = min \\parallel \\hat{A}\\hat{x} - y \\parallel $\n",
    "  \n",
    "### Gauss Markov\n",
    "> The OLS estimator has the lowest sampling variance in the class of linear unbiased estimators; in other words, the OLS is BLUE (Gauss-Markov).\n",
    "- In real world, noise is included in model: $ y = \\alpha^tX+\\epsilon$\n",
    "- In particular we assume that the noise has mean zero and finite variance : $ E[\\epsilon] = 0 ; Var(\\epsilon) = \\sigma^2 $\n",
    "- We are interested in estimating x hat, the solution to the following problem, which is itself a random variable, because y is a random variable.\n",
    "- In particular, we are only interested in the class of linear estimators, or estimators of the form\n",
    "  $ \\hat{x} = \\sum^d_{i=1}c_iy_i$\n",
    "- That the estimator is unbiased means that: $ E[\\sum^n_{i=1}c_i(\\hat{x_i} - x_i)] = 0 $\n",
    "- The Gauss-Markov theorem simply states that the following estimator is both unbiased and has the lowest variance:\n",
    "  - $ x = (A^tA)^{-1} A^ty$\n",
    "- the best we can do to minimize variance is the estimator above\n",
    "- If we allow the estimator to be biased, then we can further reduce the variance\n",
    "  \n",
    "\n",
    "### Multicollinearity and Dummy Variables\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
